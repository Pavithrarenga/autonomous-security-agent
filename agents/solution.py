from strands import Agent, tool
from strands_tools import file_read, file_write, mem0_memory, use_llm
import boto3
from strands.models import BedrockModel
import os
import json
import sys
from datetime import datetime

os.environ["BUCKET_NAME"] = "security-agent-results"

def upload_agent_results(session, bucket_name, agent_type, repo_name, results):
    """Upload agent results to S3 with structured key."""
    try:
        s3_client = session.client('s3')
        
        # Create a structured S3 key
        date_str = datetime.utcnow().strftime('%Y/%m/%d')
        timestamp = datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')
        s3_key = f"{agent_type}_results/{date_str}/{repo_name}_{timestamp}.md"
        document=f"""# {agent_type.title()} Agent Results
                **Date:** {datetime.utcnow().isoformat()} UTC
                **Repository**: {repo_name}
                **Agent:** {agent_type.title()} Agent
                ## Results
                {results}
                
                --- End of Report ---
                *Generated by Autonomous Security Agent (ASA)*
                """
                
        
        # Upload the results
        s3_client.put_object(
            Bucket=bucket_name,
            Key=s3_key,
            Body=document.encode('utf-8'),
            ContentType='text/markdown'
        )
        
        s3_url = f"s3://{bucket_name}/{s3_key}"
        print(f"{agent_type.title()} agent results uploaded to {s3_url}")
        return s3_url
    except Exception as e:
        print(f"Error uploading {agent_type} agent results to s3: {e}")
        return f"s3 upload failed: {str(e)}"   

@tool
def autonomous_file_write(content, file_path, user_id):
    """Write content to a file without user approval."""
    try:
        print(f"Writing to file: {file_path}")
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)
        return f"File {file_path} written successfully."
    except Exception as e:
        return f"Error writing to file {file_path}: {str(e)}"


def get_solution_system_prompt(risk_assessment_content, repo_to_assess):
    return f"""
You are a vulnerability fix implementation expert with conversational memory. Your capabilities include:
1. Reading all the files within the target application at {repo_to_assess}
2. Read proposed vulnerability fixes outlined below:

{risk_assessment_content}

3. Accurately identify which file in the target application needs to be modified with the proposed vulnerability fix.
4. Show the user regarding the proposed fix, providing a before vs after comparison.
5. Go and implement the fix in the corresponding file in the {repo_to_assess}.
6. Ensure that the fix is implemented successfully and saved properly in the S3 bucket 
"""

def solution_agent(session, risk_assessment_content, repo_to_assess, user_id):
    bedrock_model = BedrockModel(
        model_id="anthropic.claude-3-5-sonnet-20241022-v2:0",
        temperature=0.3,
        top_p=0.8,
        boto_session=session,
    )

    return Agent(
        model=bedrock_model,
        system_prompt=get_solution_system_prompt(risk_assessment_content, repo_to_assess),
        tools=[file_read, autonomous_file_write, mem0_memory, use_llm],
    )

def initialize_session_memory(agent, user_id, repo_to_assess, risk_assessment_content):
    """Initialize memory with session context"""
    init_context = f"Starting vulnerability fix session for repository: {repo_to_assess}. Risk assessment content: {risk_assessment_content}. User preferences: awaits approval before implementing fixes."
    agent.tool.mem0_memory(
        action="store",
        content=init_context,
        user_id=user_id
    )

def solution_main(risk_assessment_content, repo_to_assess):
    session = boto3.Session(region_name='ap-southeast-2')
    user_id = os.getenv('USER_ID', 'security_analyst')
    
    # Read the risk assessment file
    # with open(risk_assessment, "r", encoding="utf-8") as f:
    #     risk_assessment_content = f.read()
    
    # Create agent with context and memory
    agent = solution_agent(session, risk_assessment_content, repo_to_assess, user_id)
    
    # Initialize session memory
    initialize_session_memory(agent, user_id, repo_to_assess, risk_assessment_content)
    
    print("Solution Agent initialized with conversational memory.")
    print(f"Repository to assess: {repo_to_assess}")
    print(f"Risk assessment: {risk_assessment_content}")
    print(f"User ID: {user_id}")
    print("\n" + "="*50)
    
    # Start conversational fix process
    initial_prompt = "Please analyze the vulnerability fixes needed, and describe only the first fix you can suggest with a before/after comparison. Then, implement the fix in the corresponding file in the code."
    
    response = agent(initial_prompt, user_id=user_id)
    print(response)
    # Upload results to S3
    bucket_name = 'security-agent-results'
    repo_name = os.path.basename(repo_to_assess)
    upload_result = upload_agent_results(session, bucket_name, "solution", repo_name, str(response))
    print(f"s3 upload result: {upload_result}")
    return str(response)
    # Interactive conversational loop
    # while True:
    #     user_input = input("\n> ").strip()
        
    #     if user_input.lower() in ['quit', 'exit']:
    #         # Store session end in memory
    #         agent.tool.mem0_memory(
    #             action="store",
    #             content="Session ended by user.",
    #             user_id=user_id
    #         )
    #         print("Exiting solution agent.")
    #         break
        
    #     # Process user input with conversational context
    #     response = agent(user_input, user_id=user_id)
    #     print(response)

# if __name__ == "__main__":
#     solution_main()

# def solution_main(risk_assessment_content, repo_to_assess):
#     session = boto3.Session(region_name='ap-southeast-2')
#     user_id = os.getenv('USER_ID', 'security_analyst')
    
#     agent = solution_agent(session, risk_assessment_content, repo_to_assess, user_id)
#     initialize_session_memory(agent, user_id, repo_to_assess, risk_assessment_content)
    
#     # Get first proposed fix (no interactive loop)
#     initial_prompt = "Analyze the vulnerability fixes and propose the FIRST fix with before/after comparison. Be concise."
    
#     response = agent(initial_prompt, user_id=user_id)
    
#     return str(response)  # Return the response instead of looping